{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c9ba85",
   "metadata": {},
   "source": [
    "# Linear Regression: Three Implementation Approaches\n",
    "\n",
    "This notebook demonstrates linear regression using three different approaches:\n",
    "1. **Scikit-learn**\n",
    "2. **Closed-form solution** - The analytical approach (Normal Equation)\n",
    "3. **Gradient descent** - The optimization approach (generally wouldn't do this one, it's just to build gradient descent intuition)\n",
    "\n",
    "We'll use the USA Housing dataset to predict house prices based on various features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b516b",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import kagglehub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f75b5",
   "metadata": {},
   "source": [
    "## Load USA Housing Dataset\n",
    "\n",
    "We'll use the USA Housing dataset from Kaggle which contains housing data\n",
    "with features like average area income, house age, number of rooms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the USA Housing dataset from Kaggle\n",
    "print(\"Downloading USA Housing dataset from Kaggle...\")\n",
    "path = kagglehub.dataset_download(\"vedavyasv/usa-housing\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import os\n",
    "dataset_files = os.listdir(path)\n",
    "print(\"Files in dataset:\", dataset_files)\n",
    "\n",
    "# Load the CSV file\n",
    "csv_files = [f for f in dataset_files if f.endswith('.csv')]\n",
    "dataset_file = csv_files[0]  # Take the first CSV file\n",
    "df = pd.read_csv(os.path.join(path, dataset_file))\n",
    "print(f\"\\nLoaded dataset: {dataset_file}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dced7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the dataset structure\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587fbffb",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb650cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names (remove spaces, make lowercase)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "print(\"Cleaned column names:\", list(df.columns))\n",
    "\n",
    "# Display sample of the data\n",
    "print(f\"\\nSample of cleaned data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target and features\n",
    "# The target is typically 'price' in housing datasets\n",
    "target_col = 'price'\n",
    "\n",
    "# Get all numeric features except target\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target_col in numeric_features:\n",
    "    numeric_features.remove(target_col)\n",
    "\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "print(f\"Target variable: {target_col}\")\n",
    "\n",
    "# Remove any non-numeric or problematic columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3c36a",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "Below, we do some normal data preprocessing steps. They're not necessary in this dataset but I want to point out that they're frequently necessary on data that is not as clean as Kaggle data i.e. most real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values and prepare data\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove rows with missing target values\n",
    "df_clean = df_clean.dropna(subset=[target_col])\n",
    "\n",
    "# Handle missing values in features (fill with median)\n",
    "for col in numeric_features:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")\n",
    "print(f\"Missing values after cleaning:\\n{df_clean[numeric_features + [target_col]].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2f7a4",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ad3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis\n",
    "print(f\"Target variable ({target_col}) statistics:\")\n",
    "print(df_clean[target_col].describe())\n",
    "\n",
    "# Plot target distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df_clean[target_col], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Distribution of {target_col}')\n",
    "plt.xlabel(target_col)\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df_clean[target_col])\n",
    "plt.title(f'Boxplot of {target_col}')\n",
    "plt.ylabel(target_col)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Log scale if values are very skewed\n",
    "if df_clean[target_col].min() > 0:\n",
    "    plt.hist(np.log1p(df_clean[target_col]), bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.title(f'Log Distribution of {target_col}')\n",
    "    plt.xlabel(f'log({target_col})')\n",
    "else:\n",
    "    plt.scatter(range(len(df_clean)), df_clean[target_col], alpha=0.5)\n",
    "    plt.title(f'{target_col} vs Index')\n",
    "    plt.xlabel('Index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95a3c5",
   "metadata": {},
   "source": [
    "### Feature analysis\n",
    "Feature analysis and correlation. Generally if two features are highly, highly correlated\n",
    "it is bad to include both of them without some additional tricks. If you're interested in \n",
    "in learning more, the relevant term is \"multi-collinearity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f16938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature statistics:\")\n",
    "print(df_clean[numeric_features].describe())\n",
    "\n",
    "# Correlation analysis\n",
    "correlation_data = df_clean[numeric_features + [target_col]]\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = correlation_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, fmt='.3f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlations with target\n",
    "target_correlations = correlation_matrix[target_col].abs().sort_values(ascending=False)\n",
    "print(f\"\\nFeatures most correlated with {target_col}:\")\n",
    "print(target_correlations[1:])  # Exclude self-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6788b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of features vs target\n",
    "n_features = len(numeric_features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, feature in enumerate(numeric_features):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    \n",
    "    axes[row, col].scatter(df_clean[feature], df_clean[target_col], alpha=0.5)\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel(target_col)\n",
    "    axes[row, col].set_title(f'{feature} vs {target_col}')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df_clean[feature], df_clean[target_col], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[row, col].plot(df_clean[feature], p(df_clean[feature]), \"r--\", alpha=0.8)\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(n_features, n_rows * n_cols):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b165b",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e4ee9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_clean[numeric_features].values\n",
    "y = df_clean[target_col].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"Feature names: {numeric_features}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fd22d",
   "metadata": {},
   "source": [
    "### Data Standardization (Z-Score Normalization)\n",
    "If you look at the data exploration, you'll notice that some of the values are huge: in the millions! If we take the square of that, our loss will be gigantic. It'll put us into issues of numerical instability (running out of numbers on the computer). So, very often, we'll do what's called \"standardization\" of the features.\n",
    "\n",
    "**Why standardization is crucial for linear regression:**\n",
    "1. **Numerical stability**: Prevents ill-conditioned matrices\n",
    "2. **Fair feature comparison**: Features with different scales won't dominate\n",
    "3. **Gradient descent convergence**: Ensures similar learning rates for all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc32634",
   "metadata": {},
   "source": [
    "### Explicit Standardization Implementation\n",
    "\n",
    "Let's implement standardization from scratch to understand exactly what it means:\n",
    "\n",
    "**Standardization Formula (Z-Score):**\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Where:\n",
    "- $x$ = original feature value\n",
    "- $\\mu$ = mean of the feature\n",
    "- $\\sigma$ = standard deviation of the feature\n",
    "- $z$ = standardized feature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit standardization implementation\n",
    "def standardize_features(X_train, X_test=None):\n",
    "    \"\"\"\n",
    "    Explicitly standardize features by subtracting mean and dividing by std\n",
    "    \n",
    "    Returns:\n",
    "        X_train_standardized, X_test_standardized, feature_means, feature_stds\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate mean and std from training data\n",
    "    feature_means = np.mean(X_train, axis=0)\n",
    "    feature_stds = np.std(X_train, axis=0, ddof=1)  # Use sample std (ddof=1)\n",
    "    \n",
    "    # Step 2: Apply standardization transformation\n",
    "    # z = (x - μ) / σ\n",
    "    X_train_standardized = (X_train - feature_means) / feature_stds\n",
    "    \n",
    "    if X_test is not None:\n",
    "        # Use training statistics for test set (important!)\n",
    "        X_test_standardized = (X_test - feature_means) / feature_stds\n",
    "        return X_train_standardized, X_test_standardized, feature_means, feature_stds\n",
    "    \n",
    "    return X_train_standardized, feature_means, feature_stds\n",
    "\n",
    "def standardize_target(y_train, y_test=None):\n",
    "    \"\"\"\n",
    "    Explicitly standardize target variable\n",
    "    \"\"\"\n",
    "    target_mean = np.mean(y_train)\n",
    "    target_std = np.std(y_train, ddof=1)\n",
    "    \n",
    "    y_train_standardized = (y_train - target_mean) / target_std\n",
    "    \n",
    "    if y_test is not None:\n",
    "        y_test_standardized = (y_test - target_mean) / target_std\n",
    "        return y_train_standardized, y_test_standardized, target_mean, target_std\n",
    "    \n",
    "    return y_train_standardized, target_mean, target_std\n",
    "\n",
    "def inverse_standardize_target(y_standardized, target_mean, target_std):\n",
    "    \"\"\"\n",
    "    Transform standardized predictions back to original scale\n",
    "    \"\"\"\n",
    "    return y_standardized * target_std + target_mean\n",
    "\n",
    "# Apply explicit standardization\n",
    "print(\"Applying Explicit Standardization...\")\n",
    "X_train_scaled, X_test_scaled, feature_means, feature_stds = standardize_features(X_train, X_test)\n",
    "y_train_scaled, y_test_scaled, target_mean, target_std = standardize_target(y_train, y_test)\n",
    "\n",
    "print(f\"Feature Standardization Results:\")\n",
    "print(f\"=\" * 40)\n",
    "print(f\"Original feature means: {X_train.mean(axis=0).round(2)}\")\n",
    "print(f\"Original feature stds:  {X_train.std(axis=0, ddof=1).round(2)}\")\n",
    "print(f\"Computed feature means: {feature_means.round(2)}\")\n",
    "print(f\"Computed feature stds:  {feature_stds.round(2)}\")\n",
    "\n",
    "print(f\"\\nAfter standardization:\")\n",
    "print(f\"Standardized feature means: {X_train_scaled.mean(axis=0).round(6)}\")  # Should be ~0\n",
    "print(f\"Standardized feature stds:  {X_train_scaled.std(axis=0, ddof=1).round(6)}\")   # Should be ~1\n",
    "\n",
    "print(f\"\\nTarget Variable Standardization:\")\n",
    "print(f\"Original target mean: {y_train.mean():.2f}, std: {y_train.std(ddof=1):.2f}\")\n",
    "print(f\"Computed target mean: {target_mean:.2f}, std: {target_std:.2f}\")\n",
    "print(f\"Standardized target mean: {y_train_scaled.mean():.6f}, std: {y_train_scaled.std(ddof=1):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe5029",
   "metadata": {},
   "source": [
    "### Step-by-Step Standardization Demonstration\n",
    "\n",
    "Let's see standardization in action for a single feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate standardization step-by-step for first feature\n",
    "feature_idx = 0\n",
    "feature_name = numeric_features[feature_idx]\n",
    "\n",
    "print(f\"Standardization demonstration for feature: '{feature_name}'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Original values (first 10 samples)\n",
    "original_values = X_train[:10, feature_idx]\n",
    "print(f\"Original values (first 10): {original_values.round(2)}\")\n",
    "\n",
    "# Step 1: Calculate statistics\n",
    "mean_val = feature_means[feature_idx]\n",
    "std_val = feature_stds[feature_idx]\n",
    "print(f\"\\nStep 1 - Calculate statistics:\")\n",
    "print(f\"  Mean (μ): {mean_val:.2f}\")\n",
    "print(f\"  Std (σ):  {std_val:.2f}\")\n",
    "\n",
    "# Step 2: Apply standardization formula\n",
    "print(f\"\\nStep 2 - Apply standardization: z = (x - μ) / σ\")\n",
    "standardized_values = X_train_scaled[:10, feature_idx]\n",
    "for i in range(5):  # Show first 5 calculations\n",
    "    original = original_values[i]\n",
    "    standardized = standardized_values[i]\n",
    "    manual_calc = (original - mean_val) / std_val\n",
    "    print(f\"  Sample {i+1}: ({original:.2f} - {mean_val:.2f}) / {std_val:.2f} = {manual_calc:.3f} ≈ {standardized:.3f}\")\n",
    "\n",
    "print(f\"\\nStandardized values (first 10): {standardized_values.round(3)}\")\n",
    "print(f\"Verification - Standardized mean: {standardized_values.mean():.6f} (should be ~0)\")\n",
    "print(f\"Verification - Standardized std:  {standardized_values.std(ddof=1):.6f} (should be ~1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d03937",
   "metadata": {},
   "source": [
    "## Method 1: Scikit-learn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4caca76",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Train scikit-learn linear regression on standardized data\n",
    "print(\"Training Scikit-learn Linear Regression on Standardized Data...\")\n",
    "sklearn_lr = LinearRegression()\n",
    "sklearn_lr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Make predictions (in scaled space)\n",
    "sklearn_pred_train_scaled = sklearn_lr.predict(X_train_scaled)\n",
    "sklearn_pred_test_scaled = sklearn_lr.predict(X_test_scaled)\n",
    "\n",
    "# Transform predictions back to original scale using our explicit function\n",
    "sklearn_pred_train = inverse_standardize_target(sklearn_pred_train_scaled, target_mean, target_std)\n",
    "sklearn_pred_test = inverse_standardize_target(sklearn_pred_test_scaled, target_mean, target_std)\n",
    "\n",
    "# Calculate metrics in original scale\n",
    "sklearn_train_mse = mean_squared_error(y_train, sklearn_pred_train)\n",
    "sklearn_test_mse = mean_squared_error(y_test, sklearn_pred_test)\n",
    "sklearn_train_r2 = r2_score(y_train, sklearn_pred_train)\n",
    "sklearn_test_r2 = r2_score(y_test, sklearn_pred_test)\n",
    "\n",
    "# Also calculate metrics in scaled space for comparison\n",
    "sklearn_train_mse_scaled = mean_squared_error(y_train_scaled, sklearn_pred_train_scaled)\n",
    "sklearn_test_mse_scaled = mean_squared_error(y_test_scaled, sklearn_pred_test_scaled)\n",
    "\n",
    "print(f\"Scikit-learn Results (Original Scale):\")\n",
    "print(f\"  Train MSE: {sklearn_train_mse:.2f}\")\n",
    "print(f\"  Test MSE:  {sklearn_test_mse:.2f}\")\n",
    "print(f\"  Train R²:  {sklearn_train_r2:.4f}\")\n",
    "print(f\"  Test R²:   {sklearn_test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nScikit-learn Results (Scaled Space):\")\n",
    "print(f\"  Train MSE: {sklearn_train_mse_scaled:.6f}\")\n",
    "print(f\"  Test MSE:  {sklearn_test_mse_scaled:.6f}\")\n",
    "print(f\"  Coefficients (scaled): {sklearn_lr.coef_}\")\n",
    "print(f\"  Intercept (scaled): {sklearn_lr.intercept_:.6f}\")  # Should be ~0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a152d5c",
   "metadata": {},
   "source": [
    "## Method 2: Closed-Form Solution (Normal Equation)\n",
    "\n",
    "The closed-form solution for linear regression is:\n",
    "$$\\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$$\n",
    "\n",
    "This gives us the optimal weights directly without iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07209ec5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class LinearRegressionClosedForm:\n",
    "    \"\"\"Linear Regression using the Normal Equation (Closed-Form Solution)\"\"\"\n",
    "    \n",
    "    def __init__(self, method='solve'):\n",
    "        self.weights = None\n",
    "        self.intercept = None\n",
    "        self.method = method  # 'solve', 'pinv', or 'inv'\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using the normal equation\"\"\"\n",
    "        # Add bias term (intercept) by adding a column of ones\n",
    "        X_with_bias = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        \n",
    "        if self.method == 'solve':\n",
    "            # Method 1: Linear solver (RECOMMENDED)\n",
    "            # Solve: (X^T X) w = X^T y\n",
    "            # This is more numerically stable and efficient than computing the inverse\n",
    "            XTX = X_with_bias.T @ X_with_bias\n",
    "            XTy = X_with_bias.T @ y\n",
    "            self.weights_with_bias = np.linalg.solve(XTX, XTy)\n",
    "            \n",
    "        elif self.method == 'pinv':\n",
    "            # Method 2: Pseudo-inverse (handles singular matrices i.e. noninvertible matrices correctly but is less efficient)\n",
    "            self.weights_with_bias = np.linalg.pinv(X_with_bias) @ y\n",
    "            \n",
    "        elif self.method == 'inv':\n",
    "            # Method 3: Direct matrix inversion (NOT RECOMMENDED - numerically unstable)\n",
    "            try:\n",
    "                XTX = X_with_bias.T @ X_with_bias\n",
    "                XTX_inv = np.linalg.inv(XTX)\n",
    "                self.weights_with_bias = XTX_inv @ X_with_bias.T @ y\n",
    "            except np.linalg.LinAlgError:\n",
    "                print(\"Matrix is singular, falling back to pseudo-inverse\")\n",
    "                self.weights_with_bias = np.linalg.pinv(X_with_bias) @ y\n",
    "        \n",
    "        # Separate intercept and weights\n",
    "        self.intercept = self.weights_with_bias[0]\n",
    "        self.weights = self.weights_with_bias[1:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        return X @ self.weights + self.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03a6c1",
   "metadata": {},
   "source": [
    "### Comparing Different Closed-Form Approaches\n",
    "\n",
    "Let's compare three ways to solve the normal equation and understand their trade-offs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Compare different closed-form methods\n",
    "methods_closed = ['solve', 'pinv', 'inv']\n",
    "closed_form_results = {}\n",
    "\n",
    "print(\"Comparing Closed-Form Solution Methods:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method in methods_closed:\n",
    "    print(f\"\\nTesting method: {method}\")\n",
    "    \n",
    "    # Time the training\n",
    "    start_time = time.time()\n",
    "    model = LinearRegressionClosedForm(method=method)\n",
    "    model.fit(X_train_scaled, y_train_scaled)  # Use standardized data\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions (in scaled space then transform back)\n",
    "    pred_test_scaled = model.predict(X_test_scaled)\n",
    "    pred_test = inverse_standardize_target(pred_test_scaled, target_mean, target_std)\n",
    "    \n",
    "    # Calculate metrics in original scale\n",
    "    mse = mean_squared_error(y_test, pred_test)\n",
    "    r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    closed_form_results[method] = {\n",
    "        'model': model,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'time': training_time,\n",
    "        'weights': model.weights.copy(),\n",
    "        'intercept': model.intercept,\n",
    "        'pred_test': pred_test,\n",
    "        'pred_test_scaled': pred_test_scaled\n",
    "    }\n",
    "    \n",
    "    print(f\"  Training time: {training_time:.6f} seconds\")\n",
    "    print(f\"  Test MSE: {mse:.2f}\")\n",
    "    print(f\"  Test R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43173f2a",
   "metadata": {},
   "source": [
    "### Understanding the Differences\n",
    "\n",
    "1. **Linear Solver (`np.linalg.solve`)** - RECOMMENDED THOUGH READ THE WARNING\n",
    "   - Solves the system $(X^T X) w = X^T y$ directly\n",
    "   - Most numerically stable and efficient\n",
    "   - Uses LU decomposition internally\n",
    "   - Fails only if matrix is truly singular\n",
    "   - WARNING: I'm using np.linalg.solve here for didactic reasons, in reality you would probably use np.linalg.lstsq which is more numerically stable but I wanted you to see the explicit use of $X^T X$. It's hard to explain much more without going into numerical linear algebra.  \n",
    "\n",
    "2. **Pseudo-inverse (`np.linalg.pinv`)**\n",
    "   - Computes $w = X^{\\dagger} y$ where $X^{\\dagger}$ is the pseudo-inverse\n",
    "   - Handles singular/rank-deficient matrices\n",
    "   - More expensive computationally (uses SVD)\n",
    "   - Always produces a solution (minimum norm solution for underdetermined systems)\n",
    "\n",
    "3. **Direct Inversion (`np.linalg.inv`)** - NOT RECOMMENDED\n",
    "   - Explicitly computes $(X^T X)^{-1}$ then multiplies\n",
    "   - Numerically unstable (amplifies rounding errors)\n",
    "   - More expensive than solve\n",
    "   - Fails for singular matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4158d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Use the linear solver results for the rest of the notebook\n",
    "print(f\"\\nUsing Linear Solver method for remaining analysis...\")\n",
    "closedform_lr = closed_form_results['solve']['model']\n",
    "\n",
    "# Get the already computed predictions (properly scaled)\n",
    "closedform_pred_test = closed_form_results['solve']['pred_test']\n",
    "closedform_test_mse = closed_form_results['solve']['mse']\n",
    "closedform_test_r2 = closed_form_results['solve']['r2']\n",
    "\n",
    "# Make train predictions with proper scaling\n",
    "closedform_pred_train_scaled = closedform_lr.predict(X_train_scaled)\n",
    "closedform_pred_train = inverse_standardize_target(closedform_pred_train_scaled, target_mean, target_std)\n",
    "\n",
    "# Calculate train metrics\n",
    "closedform_train_mse = mean_squared_error(y_train, closedform_pred_train)\n",
    "closedform_train_r2 = r2_score(y_train, closedform_pred_train)\n",
    "\n",
    "print(f\"Final Closed-Form Results (Linear Solver):\")\n",
    "print(f\"  Train MSE: {closedform_train_mse:.2f}\")\n",
    "print(f\"  Test MSE:  {closedform_test_mse:.2f}\")\n",
    "print(f\"  Train R²:  {closedform_train_r2:.4f}\")\n",
    "print(f\"  Test R²:   {closedform_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c0f16",
   "metadata": {},
   "source": [
    "### Benefits of Standardization\n",
    "\n",
    "By standardizing our data, we've achieved:\n",
    "1. **Better numerical stability**: Lower condition numbers\n",
    "2. **Faster convergence**: Gradient descent converges more reliably\n",
    "3. **Fair feature weighting**: All features contribute equally to the optimization\n",
    "4. **Consistent scaling**: Coefficients are now comparable across features\n",
    "5. **Near-zero intercept**: In scaled space, intercept should be ~0 (since target is centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8bfe2",
   "metadata": {},
   "source": [
    "## Method 3: Gradient Descent Implementation\n",
    "\n",
    "Gradient descent iteratively updates weights using:\n",
    "$$\\mathbf{w} = \\mathbf{w} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{w}}$$\n",
    "\n",
    "Where the gradient for linear regression is:\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{m} \\mathbf{X}^T (\\mathbf{X}\\mathbf{w} - \\mathbf{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    \"\"\"Linear Regression using Gradient Descent\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.weights = None\n",
    "        self.intercept = None\n",
    "        self.cost_history = []\n",
    "        \n",
    "    def compute_cost(self, X, y):\n",
    "        \"\"\"Compute mean squared error cost\"\"\"\n",
    "        m = len(y)\n",
    "        predictions = X @ self.weights + self.intercept\n",
    "        cost = (1/(2*m)) * np.sum((predictions - y)**2)\n",
    "        return cost\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the model using gradient descent\"\"\"\n",
    "        m, n = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = np.random.normal(0, 0.01, n)\n",
    "        self.intercept = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Forward pass\n",
    "            predictions = X @ self.weights + self.intercept\n",
    "            \n",
    "            # Compute cost\n",
    "            cost = self.compute_cost(X, y)\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1/m) * X.T @ (predictions - y)\n",
    "            db = (1/m) * np.sum(predictions - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.intercept -= self.learning_rate * db\n",
    "            \n",
    "            # Check for convergence\n",
    "            if i > 0 and abs(self.cost_history[-2] - self.cost_history[-1]) < self.tolerance:\n",
    "                print(f\"Converged after {i+1} iterations\")\n",
    "                break\n",
    "                \n",
    "        print(f\"Final cost: {cost:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        return X @ self.weights + self.intercept\n",
    "\n",
    "# Train gradient descent model on standardized data\n",
    "print(\"Training Gradient Descent Linear Regression on Standardized Data...\")\n",
    "gd_lr = LinearRegressionGD(learning_rate=0.01, max_iterations=2000)\n",
    "gd_lr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Make predictions (in scaled space then transform back)\n",
    "gd_pred_train_scaled = gd_lr.predict(X_train_scaled)\n",
    "gd_pred_test_scaled = gd_lr.predict(X_test_scaled)\n",
    "\n",
    "# Transform predictions back to original scale using our explicit function\n",
    "gd_pred_train = inverse_standardize_target(gd_pred_train_scaled, target_mean, target_std)\n",
    "gd_pred_test = inverse_standardize_target(gd_pred_test_scaled, target_mean, target_std)\n",
    "\n",
    "# Calculate metrics in original scale\n",
    "gd_train_mse = mean_squared_error(y_train, gd_pred_train)\n",
    "gd_test_mse = mean_squared_error(y_test, gd_pred_test)\n",
    "gd_train_r2 = r2_score(y_train, gd_pred_train)\n",
    "gd_test_r2 = r2_score(y_test, gd_pred_test)\n",
    "\n",
    "# Also calculate metrics in scaled space\n",
    "gd_train_mse_scaled = mean_squared_error(y_train_scaled, gd_pred_train_scaled)\n",
    "gd_test_mse_scaled = mean_squared_error(y_test_scaled, gd_pred_test_scaled)\n",
    "\n",
    "print(f\"Gradient Descent Results (Original Scale):\")\n",
    "print(f\"  Train MSE: {gd_train_mse:.2f}\")\n",
    "print(f\"  Test MSE:  {gd_test_mse:.2f}\")\n",
    "print(f\"  Train R²:  {gd_train_r2:.4f}\")\n",
    "print(f\"  Test R²:   {gd_test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nGradient Descent Results (Scaled Space):\")\n",
    "print(f\"  Train MSE: {gd_train_mse_scaled:.6f}\")\n",
    "print(f\"  Test MSE:  {gd_test_mse_scaled:.6f}\")\n",
    "print(f\"  Coefficients (scaled): {gd_lr.weights}\")\n",
    "print(f\"  Intercept (scaled): {gd_lr.intercept:.6f}\")  # Should be ~0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bfb6a",
   "metadata": {},
   "source": [
    "## Comprehensive Comparison of All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison summary\n",
    "methods = ['Scikit-learn', 'Closed-Form', 'Gradient Descent']\n",
    "train_mse = [sklearn_train_mse, closedform_train_mse, gd_train_mse]\n",
    "test_mse = [sklearn_test_mse, closedform_test_mse, gd_test_mse]\n",
    "train_r2 = [sklearn_train_r2, closedform_train_r2, gd_train_r2]\n",
    "test_r2 = [sklearn_test_r2, closedform_test_r2, gd_test_r2]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': methods,\n",
    "    'Train MSE': train_mse,\n",
    "    'Test MSE': test_mse,\n",
    "    'Train R²': train_r2,\n",
    "    'Test R²': test_r2\n",
    "})\n",
    "\n",
    "print(\"Method Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Debug: Check if any values are abnormally large\n",
    "print(f\"\\nDebugging - Check for scaling issues:\")\n",
    "print(f\"Sklearn test MSE: {sklearn_test_mse:.2f}\")\n",
    "print(f\"Closed-form test MSE: {closedform_test_mse:.2f}\")\n",
    "print(f\"Gradient descent test MSE: {gd_test_mse:.2f}\")\n",
    "\n",
    "# Check prediction ranges\n",
    "print(f\"\\nPrediction ranges (should be similar):\")\n",
    "print(f\"Sklearn predictions: [{sklearn_pred_test.min():.2f}, {sklearn_pred_test.max():.2f}]\")\n",
    "print(f\"Closed-form predictions: [{closedform_pred_test.min():.2f}, {closedform_pred_test.max():.2f}]\")\n",
    "print(f\"Gradient descent predictions: [{gd_pred_test.min():.2f}, {gd_pred_test.max():.2f}]\")\n",
    "print(f\"Actual values: [{y_test.min():.2f}, {y_test.max():.2f}]\")\n",
    "\n",
    "# Check if there are any NaN or infinite values\n",
    "print(f\"\\nChecking for invalid values:\")\n",
    "print(f\"Sklearn pred NaN: {np.isnan(sklearn_pred_test).sum()}, Inf: {np.isinf(sklearn_pred_test).sum()}\")\n",
    "print(f\"Closed-form pred NaN: {np.isnan(closedform_pred_test).sum()}, Inf: {np.isinf(closedform_pred_test).sum()}\")\n",
    "print(f\"Gradient descent pred NaN: {np.isnan(gd_pred_test).sum()}, Inf: {np.isinf(gd_pred_test).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25937d",
   "metadata": {},
   "source": [
    "## Visualizing the Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515aa3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Cost function for gradient descent\n",
    "axes[0, 0].plot(gd_lr.cost_history)\n",
    "axes[0, 0].set_title('Gradient Descent: Cost Function')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Cost (MSE)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Performance comparison\n",
    "x_pos = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 1].bar(x_pos - width/2, test_mse, width, label='Test MSE', alpha=0.8)\n",
    "axes[0, 1].bar(x_pos + width/2, train_mse, width, label='Train MSE', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Method')\n",
    "axes[0, 1].set_ylabel('MSE')\n",
    "axes[0, 1].set_title('MSE Comparison')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels(methods)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. R² comparison\n",
    "axes[0, 2].bar(x_pos - width/2, test_r2, width, label='Test R²', alpha=0.8)\n",
    "axes[0, 2].bar(x_pos + width/2, train_r2, width, label='Train R²', alpha=0.8)\n",
    "axes[0, 2].set_xlabel('Method')\n",
    "axes[0, 2].set_ylabel('R² Score')\n",
    "axes[0, 2].set_title('R² Score Comparison')\n",
    "axes[0, 2].set_xticks(x_pos)\n",
    "axes[0, 2].set_xticklabels(methods)\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# 4. Predictions vs Actual (Test Set) - Scikit-learn\n",
    "axes[1, 0].scatter(y_test, sklearn_pred_test, alpha=0.6)\n",
    "axes[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual Values')\n",
    "axes[1, 0].set_ylabel('Predicted Values')\n",
    "axes[1, 0].set_title('Scikit-learn: Predictions vs Actual')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Predictions vs Actual (Test Set) - Closed Form\n",
    "axes[1, 1].scatter(y_test, closedform_pred_test, alpha=0.6)\n",
    "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 1].set_xlabel('Actual Values')\n",
    "axes[1, 1].set_ylabel('Predicted Values')\n",
    "axes[1, 1].set_title('Closed-Form: Predictions vs Actual')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Predictions vs Actual (Test Set) - Gradient Descent\n",
    "axes[1, 2].scatter(y_test, gd_pred_test, alpha=0.6)\n",
    "axes[1, 2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 2].set_xlabel('Actual Values')\n",
    "axes[1, 2].set_ylabel('Predicted Values')\n",
    "axes[1, 2].set_title('Gradient Descent: Predictions vs Actual')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083e66a",
   "metadata": {},
   "source": [
    "## Coefficient Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3926c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the learned coefficients\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': numeric_features,\n",
    "    'Scikit-learn': sklearn_lr.coef_,\n",
    "    'Closed-Form': closedform_lr.weights,\n",
    "    'Gradient Descent': gd_lr.weights\n",
    "})\n",
    "\n",
    "print(\"Coefficient Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(coefficients_df.round(6))\n",
    "\n",
    "# Visualize coefficient comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar plot of coefficients\n",
    "x_pos = np.arange(len(numeric_features))\n",
    "width = 0.25\n",
    "\n",
    "axes[0].bar(x_pos - width, sklearn_lr.coef_, width, label='Scikit-learn', alpha=0.8)\n",
    "axes[0].bar(x_pos, closedform_lr.weights, width, label='Closed-Form', alpha=0.8)\n",
    "axes[0].bar(x_pos + width, gd_lr.weights, width, label='Gradient Descent', alpha=0.8)\n",
    "axes[0].set_xlabel('Features')\n",
    "axes[0].set_ylabel('Coefficient Value')\n",
    "axes[0].set_title('Coefficient Comparison Across Methods')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(numeric_features, rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "\n",
    "# Correlation between coefficients\n",
    "axes[1].scatter(sklearn_lr.coef_, closedform_lr.weights, alpha=0.7, label='Sklearn vs Closed-Form')\n",
    "axes[1].scatter(sklearn_lr.coef_, gd_lr.weights, alpha=0.7, label='Sklearn vs Gradient Descent')\n",
    "axes[1].plot([sklearn_lr.coef_.min(), sklearn_lr.coef_.max()], \n",
    "             [sklearn_lr.coef_.min(), sklearn_lr.coef_.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Scikit-learn Coefficients')\n",
    "axes[1].set_ylabel('Other Method Coefficients')\n",
    "axes[1].set_title('Coefficient Correlation')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlations\n",
    "sklearn_vs_closed = np.corrcoef(sklearn_lr.coef_, closedform_lr.weights)[0, 1]\n",
    "sklearn_vs_gd = np.corrcoef(sklearn_lr.coef_, gd_lr.weights)[0, 1]\n",
    "closed_vs_gd = np.corrcoef(closedform_lr.weights, gd_lr.weights)[0, 1]\n",
    "\n",
    "print(f\"\\nCoefficient Correlations:\")\n",
    "print(f\"Scikit-learn vs Closed-Form: {sklearn_vs_closed:.6f}\")\n",
    "print(f\"Scikit-learn vs Gradient Descent: {sklearn_vs_gd:.6f}\")\n",
    "print(f\"Closed-Form vs Gradient Descent: {closed_vs_gd:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e4769",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "### Performance Comparison:\n",
    "All three methods should produce very similar results, demonstrating that they're solving the same optimization problem.\n",
    "In general, you'd use the sci-kit learn one which internally will set up the linear regression equations and solve the linear equation defining beta. But, it's important to know the little details for when things go awry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analysis complete!\")\n",
    "print(f\"\\nFinal Comparison Summary:\")\n",
    "print(f\"All methods achieved similar performance:\")\n",
    "for i, method in enumerate(methods):\n",
    "    print(f\"  {method:15}: Test R² = {test_r2[i]:.4f}, Test MSE = {test_mse[i]:.2f}\")\n",
    "\n",
    "print(f\"\\nThis demonstrates that all three approaches solve the same linear regression problem!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b26e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
